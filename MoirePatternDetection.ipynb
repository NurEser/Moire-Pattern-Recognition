{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82PBVtj47QrF"
      },
      "source": [
        "# Universal Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OiwjR3b7bJy"
      },
      "outputs": [],
      "source": [
        "# Bu değerleri değiştirince training data'nın resolution'ı da değişmeli pre-processingde (Haar2D).\n",
        "# Training data için width ve height bu değerlerin tam ikişer katı olmalı. (500x375 => 1000x750; 1000x750 => 2000x1500 gibi)\n",
        "WIDTH=500\n",
        "HEIGHT=375"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxmUaS56OELp"
      },
      "source": [
        "# UNZİP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6ulWgSIOHVN",
        "outputId": "4b44d285-b95c-4975-b04c-f969363a9a5b"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/fraudfull/brighttancrop/accept_crop_bright_12.zip' -d '/content/unzip_accept_12'\n",
        "!unzip '/content/drive/MyDrive/fraudfull/brighttancrop/discard_crop_bright_12.zip' -d '/content/unzip_discard_12'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOaE9E0unwbm"
      },
      "source": [
        "#Definitions and Imports\n",
        "## (For Training and Testing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElkK8u2AFzw5"
      },
      "source": [
        "## Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwBPuRFmFzCM"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import argparse\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from skimage import io\n",
        "import joblib\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import pandas as pd\n",
        "#from mCNN import createModel\n",
        "from keras.utils import np_utils  # utilities for one-hot encoding of ground truth values\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjLUBXk_FvMv"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anowk1HUzGAR"
      },
      "outputs": [],
      "source": [
        "# The convolutional layer C1 filter three 512 x 384 input images with 32 kernels of size 7 x 7 with a stride of 1 pixel. The stride of pooling layer S1 is 2 pixels. Then, the convolved images of LH and HL are merged together by taking the maximum from both the images. In the next step, the convolved image of LL is merged with the Max result by multiplying both the results (as explained in section III-B). C2-C4 has 16 kernels of size 3 x 3 with a stride of 1 pixel. S2 pools the merged features with a stride of 4. The dropout is applied to the output of S4 which has been flattened. The fully connected layer FC1 has 32 neurons and FC2 has 1 neuron. The activation of the output layer is a softmax function.\n",
        "\n",
        "# One significant observation found while analyzing the images is, when the image intensities are relatively darker, the patterns aren’t visible much. The darker regions in the image produce less Moire ́ patterns compared to the brighter regions in the image. To summarize the spread of the Moire ́ pattern in the image, spatially, and to produce this effect while training the network, we used the LL band of the image (which is the downsampled original image consisting of low frequency information) and used it as weights for LH anf HL band during the training, by directly multiplying it to the convolved and combined response of the LH and HL bands\n",
        "\n",
        "import os\n",
        "\n",
        "from keras.models import Model  # basic class for specifying and training a neural network\n",
        "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, Add, Multiply, Maximum\n",
        "\n",
        "\n",
        "def createModel(height, width, depth, num_classes):\n",
        "    #     num_epochs = 20 # 50 26 200 # we iterate 200 times over the entire training set\n",
        "    kernel_size_1 = 7  # we will use 7x7 kernels\n",
        "    kernel_size_2 = 3  # we will use 3x3 kernels\n",
        "    pool_size = 2  # we will use 2x2 pooling throughout\n",
        "    conv_depth_1 = 32  # we will initially have 32 kernels per conv. layer...\n",
        "    conv_depth_2 = 16  # ...switching to 16 after the first pooling layer\n",
        "    drop_prob_1 = 0.25  # dropout after pooling with probability 0.25\n",
        "    drop_prob_2 = 0.5  # dropout in the FC layer with probability 0.5\n",
        "    hidden_size = 32  # 128 512 the FC layer will have 512 neurons\n",
        "\n",
        "    inpLL = Input(shape=(height, width, depth), name='input_LL')  # depth goes last in TensorFlow back-end (first in Theano)\n",
        "    inpLH = Input(shape=(height, width, depth), name='input_LH')  # depth goes last in TensorFlow back-end (first in Theano)\n",
        "    inpHL = Input(shape=(height, width, depth), name='input_HL')  # depth goes last in TensorFlow back-end (first in Theano)\n",
        "    inpHH = Input(shape=(height, width, depth), name='input_HH')  # depth goes last in TensorFlow back-end (first in Theano)\n",
        "\n",
        "    conv_1_LL = Convolution2D(conv_depth_1, (kernel_size_1, kernel_size_1), padding='same', activation='relu')(inpLL)\n",
        "    conv_1_LH = Convolution2D(conv_depth_1, (kernel_size_1, kernel_size_1), padding='same', activation='relu')(inpLH)\n",
        "    conv_1_HL = Convolution2D(conv_depth_1, (kernel_size_1, kernel_size_1), padding='same', activation='relu')(inpHL)\n",
        "    conv_1_HH = Convolution2D(conv_depth_1, (kernel_size_1, kernel_size_1), padding='same', activation='relu')(inpHH)\n",
        "    pool_1_LL = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1_LL)\n",
        "    pool_1_LH = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1_LH)\n",
        "    pool_1_HL = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1_HL)\n",
        "    pool_1_HH = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1_HH)\n",
        "\n",
        "    avg_LH_HL_HH = Maximum()([pool_1_LH, pool_1_HL, pool_1_HH])\n",
        "    inp_merged = Multiply()([pool_1_LL, avg_LH_HL_HH])\n",
        "    C4 = Convolution2D(conv_depth_2, (kernel_size_2, kernel_size_2), padding='same', activation='relu')(inp_merged)\n",
        "    S2 = MaxPooling2D(pool_size=(4, 4))(C4)\n",
        "    drop_1 = Dropout(drop_prob_1)(S2)\n",
        "    C5 = Convolution2D(conv_depth_1, (kernel_size_2, kernel_size_2), padding='same', activation='relu')(drop_1)\n",
        "    S3 = MaxPooling2D(pool_size=(pool_size, pool_size))(C5)\n",
        "    C6 = Convolution2D(conv_depth_1, (kernel_size_2, kernel_size_2), padding='same', activation='relu')(S3)\n",
        "    S4 = MaxPooling2D(pool_size=(pool_size, pool_size))(C6)\n",
        "    drop_2 = Dropout(drop_prob_1)(S4)\n",
        "    # Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
        "    flat = Flatten()(drop_2)\n",
        "    hidden = Dense(hidden_size, activation='relu')(flat)\n",
        "    drop_3 = Dropout(drop_prob_2)(hidden)\n",
        "    out = Dense(num_classes, activation='softmax')(drop_3)\n",
        "\n",
        "    model = Model(inputs=[inpLL , inpLH, inpHL, inpHH],\n",
        "                  outputs=out) # To define a model, just specify its input and output layers\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P184xItF3YY"
      },
      "source": [
        "## Utility Functions\n",
        "### String Operations, Feature Scaling, Google Drive Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NP1Or_oGVxc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def scaleData(inp, minimum, maximum):\n",
        "    minMaxScaler = preprocessing.MinMaxScaler(copy=True, feature_range=(minimum, maximum))\n",
        "    inp = inp.reshape(-1, 1)\n",
        "    inp = minMaxScaler.fit_transform(inp)\n",
        "\n",
        "    return inp\n",
        "\n",
        "\n",
        "# - read positive and negative training data\n",
        "# - create X and Y from training data\n",
        "def remove_all_exts(inp):\n",
        "    \"\"\"\n",
        "    \".jpg\" Uzantısını kaldırmak için kullanıyorum.\n",
        "    Mesela  'oriented_20220122t055407_4799f9ba_457e_46ce_98e6_75693ef54a46.jpg' ->\n",
        "    'oriented_20220122t055407_4799f9ba_457e_46ce_98e6_75693ef54a46' oluyor\n",
        "    \"\"\"\n",
        "    f = inp.find(\"_LL.tiff\")\n",
        "    if f != -1:\n",
        "        return inp[:f]\n",
        "    f = inp.find(\"_HL.tiff\")\n",
        "    if f != -1:\n",
        "        return inp[:f]\n",
        "    f = inp.find(\"_LH.tiff\")\n",
        "    if f != -1:\n",
        "        return inp[:f]\n",
        "    f = inp.find(\"_HH.tiff\")\n",
        "    if f != -1:\n",
        "        return inp[:f]\n",
        "\n",
        "\n",
        "def remove_extension(inp):\n",
        "    \"\"\"\n",
        "    \".jpg\" Uzantısını kaldırmak için kullanıyorum.\n",
        "    Mesela  'oriented_20220122t055407_4799f9ba_457e_46ce_98e6_75693ef54a46.jpg' ->\n",
        "    'oriented_20220122t055407_4799f9ba_457e_46ce_98e6_75693ef54a46' oluyor\n",
        "    \"\"\"\n",
        "    return inp[:-4]\n",
        "\n",
        "def add_extension(inp,ext):\n",
        "    \"\"\"\n",
        "    \".jpg'yi kaldırdıktan sonra '_180' ve '_180_FLIP' eklemek için bunu çağırıyorum.\n",
        "    Verilen stringin ucunua uzantıyı ekliyor.\"\n",
        "    \"\"\"\n",
        "    return str(inp)+str(ext)\n",
        "\n",
        "\n",
        "def copyPathIfDrive(path):\n",
        "    import shutil\n",
        "    path_name = path[path.rfind(\"/\")+1:]\n",
        "    src = \"/content/\"+path_name\n",
        "    if os.path.exists(src):\n",
        "        print(f\"Returned {src} for {path}\")\n",
        "        return src\n",
        "    if path.find(\"drive\") != -1:\n",
        "        print(f\"Copying to {src} from {path}...\")\n",
        "        shutil.copytree(path, src)\n",
        "        print(f\"Returned {src} for {path}\")\n",
        "        return src\n",
        "    print(f\"Path {path} is not drive, won't do nothing!\")\n",
        "    return path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6oKFy1gGtyc"
      },
      "source": [
        "## Training Related Functions (Load, Read, Split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UntW7s_DG4qG"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def calculate_the_train_test_split_indices_my(X_index,Y,testCountPercent,random_seed=1):\n",
        "\n",
        "\n",
        "    X_train_ind, X_test_ind, y_train, y_test = train_test_split(X_index, Y, test_size=testCountPercent, random_state=random_seed,\n",
        "                                                                stratify=Y)\n",
        "    return X_train_ind, X_test_ind, y_train, y_test\n",
        "\n",
        "\n",
        "    #bu fonksiyonu hem test hem de validation için kullanıyorum o yüzden kaydetmemeliyim.\n",
        "    if os.path.exists(\"my_guys.pkl\"):\n",
        "      my_guys = joblib.load(\"my_guys.pkl\")\n",
        "      if my_guys[\"perc\"] != testCountPercent:\n",
        "        os.remove(\"my_guys.pkl\")\n",
        "        X_train_ind, X_test_ind, y_train, y_test = train_test_split(X_index, Y, test_size=testCountPercent, random_state=1,\n",
        "                                                        stratify=Y)\n",
        "        my_guys={\"perc\":testCountPercent,\"X_train_ind\":X_train_ind,\"X_test_ind\":X_test_ind, \"y_train\":y_train, \"y_test\":y_test}\n",
        "        joblib.dump(my_guys,\"my_guys.pkl\")\n",
        "        return X_train_ind, X_test_ind, y_train, y_test\n",
        "      X_train_ind = my_guys[\"X_train_ind\"]\n",
        "      X_test_ind = my_guys[\"X_test_ind\"]\n",
        "      y_train = my_guys[\"y_train\"]\n",
        "      y_test = my_guys[\"y_test\"]\n",
        "      return X_train_ind, X_test_ind, y_train, y_test\n",
        "    else:\n",
        "      X_train_ind, X_test_ind, y_train, y_test = train_test_split(X_index, Y, test_size=testCountPercent, random_state=1,\n",
        "                                                                stratify=Y)\n",
        "      my_guys={\"perc\":testCountPercent,\"X_train_ind\":X_train_ind,\"X_test_ind\":X_test_ind, \"y_train\":y_train, \"y_test\":y_test}\n",
        "      joblib.dump(my_guys,\"my_guys.pkl\")\n",
        "      return X_train_ind, X_test_ind, y_train, y_test\n",
        "\n",
        "\n",
        "def loadXandY(positiveTrainImagePath,negativeTrainImagePath,random_seed=1):\n",
        "    # positiveImageFiles = [f for f in listdir(positiveTrainImagePath) if (isfile(join(positiveTrainImagePath, f)))]\n",
        "    # negativeImageFiles = [f for f in listdir(negativeTrainImagePath) if (isfile(join(negativeTrainImagePath, f)))]\n",
        "\n",
        "\n",
        "    positiveImageFiles = [f for f in listdir(positiveTrainImagePath)]\n",
        "    negativeImageFiles = [f for f in listdir(negativeTrainImagePath)]\n",
        "\n",
        "    unique_maker = np.vectorize(remove_all_exts)\n",
        "\n",
        "    positiveImageFiles = np.unique(unique_maker(np.array(positiveImageFiles)))\n",
        "    negativeImageFiles = np.unique(unique_maker(np.array(negativeImageFiles)))\n",
        "\n",
        "    positiveCount = len(positiveImageFiles)\n",
        "    negativeCount = len(negativeImageFiles)\n",
        "\n",
        "    print(positiveCount)\n",
        "    print(negativeCount)\n",
        "\n",
        "    Y_all = np.zeros(positiveCount+negativeCount)\n",
        "    Y_all[:positiveCount] = 1 #Y HAZIR\n",
        "\n",
        "    X_index_all = np.concatenate([positiveImageFiles,negativeImageFiles]) #X HAZIR\n",
        "\n",
        "    \n",
        "    temp = list(zip(X_index_all, Y_all))\n",
        "    random.Random(random_seed).shuffle(temp)\n",
        "    X_index_shuff, Y_shuff = zip(*temp)\n",
        "    X_index_shuff, Y_shuff = np.array(list(X_index_shuff)), np.array(list(Y_shuff))\n",
        "    return X_index_shuff, Y_shuff\n",
        "\n",
        "\n",
        "def readAndScaleImage_my(filepath_without_tiff_nor_xx, X_LL, X_LH, X_HL, X_HH, sampleIndex):\n",
        "\n",
        "    fLL = filepath_without_tiff_nor_xx + \"_LL.tiff\"\n",
        "    fLH = filepath_without_tiff_nor_xx + \"_LH.tiff\"\n",
        "    fHL = filepath_without_tiff_nor_xx + \"_HL.tiff\"\n",
        "    fHH = filepath_without_tiff_nor_xx + \"_HH.tiff\"\n",
        "\n",
        "    try:\n",
        "        imgLL = Image.open(fLL)\n",
        "        imgLH = Image.open(fLH)\n",
        "        imgHL = Image.open(fHL)\n",
        "        imgHH = Image.open(fHH)\n",
        "    except Exception as e:\n",
        "        print('Error: Couldnt read the file {}. Make sure only images are present in the folder'.format(filepath_without_tiff_nor_xx))\n",
        "        print('Exception:', e)\n",
        "        return None\n",
        "\n",
        "    imgLL = np.array(imgLL)\n",
        "    imgLH = np.array(imgLH)\n",
        "    imgHL = np.array(imgHL)\n",
        "    imgHH = np.array(imgHH)\n",
        "    imgLL = scaleData(imgLL, 0, 1)\n",
        "    imgLH = scaleData(imgLH, -1, 1)\n",
        "    imgHL = scaleData(imgHL, -1, 1)\n",
        "    imgHH = scaleData(imgHH, -1, 1)\n",
        "\n",
        "    imgVector = imgLL.reshape(1, WIDTH * HEIGHT)\n",
        "    X_LL[sampleIndex, :] = imgVector\n",
        "    imgVector = imgLH.reshape(1, WIDTH * HEIGHT)\n",
        "    X_LH[sampleIndex, :] = imgVector\n",
        "    imgVector = imgHL.reshape(1, WIDTH * HEIGHT)\n",
        "    X_HL[sampleIndex, :] = imgVector\n",
        "    imgVector = imgHH.reshape(1, WIDTH * HEIGHT)\n",
        "    X_HH[sampleIndex, :] = imgVector\n",
        "\n",
        "    return True\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnVUNTprHjrb"
      },
      "source": [
        "## Generator and Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icqli6r5Hv0B"
      },
      "source": [
        "### Generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CU5f3ZyCHnme"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "def generate_batches(X_index_train, Y_train, batch_size, positiveTrainImagePath,negativeTrainImagePath, custom_str=\"\", infin=True, name=True):\n",
        "    \"\"\"\n",
        "    Bu bizim keras generator fonksiyonumuz. Model bu fonksiyonu çağırıyor data için bu da ilk seferinde yield kısmına kadar\n",
        "    çalışıp batch_size kadar data döndürüyor. Model bunu bundan sonra her çağırdığında yalnızca (for elem in range...) yazan for loopuna devam edip\n",
        "    bir daha yield ediyor. Yani kısaca model istedikçe bu for loopta ilerleyip bir grup daha yüklüyor.\n",
        "    \"\"\"\n",
        "    counter_global = 0\n",
        "    keep_going = True\n",
        "    while keep_going:\n",
        "        if not infin:\n",
        "            keep_going= False\n",
        "        counter_epoch = 0\n",
        "        max_length = len(X_index_train)\n",
        "        for elem in range(0,max_length,batch_size):\n",
        "\n",
        "            if elem == 0:\n",
        "                print(\"Zeroed! Restarting from the top!\")\n",
        "\n",
        "            if elem+batch_size > max_length:\n",
        "                ran = max_length-elem\n",
        "            else:\n",
        "                ran = batch_size\n",
        "\n",
        "\n",
        "            X_indices = X_index_train[elem:elem+ran]\n",
        "            Y_indices = np.asarray(Y_train[elem:elem+ran]).astype(np.float32)\n",
        "            X_LL = np.asarray(np.zeros((ran, WIDTH * HEIGHT))).astype(np.float32)\n",
        "            X_LH = np.asarray(np.zeros((ran, WIDTH * HEIGHT))).astype(np.float32)\n",
        "            X_HL = np.asarray(np.zeros((ran, WIDTH * HEIGHT))).astype(np.float32)\n",
        "            X_HH = np.asarray(np.zeros((ran, WIDTH * HEIGHT))).astype(np.float32)\n",
        "            counter_epoch += ran\n",
        "            counter_global += ran\n",
        "            print(f\"\\n{str(len(X_LL))} tane daha resim okundu. Toplam okunan: {counter_global}, Epoch'ta okunan: {counter_epoch}. {custom_str}\")\n",
        "            print(f\"Bu serideki ilk resim: {X_indices[0]} Değer:{Y_indices[0]}\")\n",
        "            print(f\"Bu serideki son resim: {X_indices[ran-1]} Değer:{Y_indices[ran-1]}\")\n",
        "\n",
        "\n",
        "\n",
        "            for i in range(ran):\n",
        "                if Y_indices[i][1] == 1: #Eğer positive ise dosya positiveTrainImagePath/'tedir\n",
        "                    path_intro = positiveTrainImagePath\n",
        "                else: #Yoksa negativeTrainImagePath'i dosya adının başına ekliyorum.\n",
        "                    path_intro = negativeTrainImagePath\n",
        "                if readAndScaleImage_my(path_intro+\"/\"+X_indices[i],X_LL,X_LH,X_HL,X_HH,i) != True: #Bu fonksiyon verdiğim arraylerin içini dolduruyor. Arraylerin büyüklüğü batch_size kadar. Her entry resim boyu kadar pixel arrayi\n",
        "                    raise Exception(\"HEY COULDN'T READ IMAGE\")\n",
        "            X_LL = X_LL.reshape((ran, HEIGHT, WIDTH, 1)) #Model datayı böyle almak istiyor. Neural network işleri. 32x500x375x1 gibi bir formata getiriyoruz. depth=1, o sondaki sayı depth için\n",
        "            X_LH = X_LH.reshape((ran, HEIGHT, WIDTH, 1))\n",
        "            X_HL = X_HL.reshape((ran, HEIGHT, WIDTH, 1))\n",
        "            X_HH = X_HH.reshape((ran, HEIGHT, WIDTH, 1))\n",
        "            if name:\n",
        "                yield {'input_LL':X_LL,'input_LH':X_LH,'input_HL': X_HL,'input_HH': X_HH},Y_indices\n",
        "            else:\n",
        "                yield [X_LL,X_LH,X_HL,X_HH],Y_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R7z8IsjH1bv"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2iOWdvwH6FK"
      },
      "outputs": [],
      "source": [
        "\n",
        "def trainCNNModel_my(X_train_ind, X_test_ind, y_train, y_test, num_epochs, batch_size, validation_batch_size, validation_percent, positiveTrainImagePath,negativeTrainImagePath):\n",
        "    \"\"\"\n",
        "    Bu yeni train fonksiyonu. Generatorü çağırıyor doğrudan array almak yerine train olurken.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    X_train_train_ind, X_validation_ind, y_train_train, y_validation = calculate_the_train_test_split_indices_my(X_train_ind,y_train,validation_percent)\n",
        "\n",
        "\n",
        "    num_train, height, width, depth = len(X_train_train_ind), HEIGHT, WIDTH ,1\n",
        "    num_val=len(X_validation_ind)\n",
        "    num_test=len(X_test_ind)\n",
        "    print(\"Train set: \" + str(num_train))\n",
        "    print(\"Validation set: \" + str(num_val))\n",
        "    print(\"Test set: \" + str(num_test))\n",
        "\n",
        "    num_classes = len(np.unique(y_train)) #2\n",
        "    y_train_train = y_train_train.reshape(len(y_train_train),1)\n",
        "    y_validation = y_validation.reshape(len(y_validation),1)\n",
        "    y_test = y_test.reshape(len(y_test),1)\n",
        "\n",
        "    Y_train_train = np_utils.to_categorical(y_train_train, num_classes)  # One-hot encode the labels\n",
        "    Y_validation = np_utils.to_categorical(y_validation, num_classes)  # One-hot encode the labels\n",
        "    Y_test = np_utils.to_categorical(y_test, num_classes)  # One-hot encode the labels\n",
        "\n",
        "\n",
        "\n",
        "    checkPointFolder = 'checkPoint2'\n",
        "    checkpoint_name = checkPointFolder + '/Weights-{epoch:03d}--{val_loss:.5f}.hdf5'\n",
        "    checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "    callbacks_list = [checkpoint]\n",
        "    if not os.path.exists(checkPointFolder):\n",
        "        os.makedirs(checkPointFolder)\n",
        "\n",
        "    model = createModel(height, width, depth, num_classes)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',  # using the cross-entropy loss function\n",
        "                  optimizer='adam',  # using the Adam optimiser\n",
        "                  metrics=['accuracy'])  # reporting the accuracy\n",
        "\n",
        "    generator_x = generate_batches(X_train_train_ind,Y_train_train,batch_size,positiveTrainImagePath,negativeTrainImagePath, \"(Train Generator)\")\n",
        "\n",
        "    validation_dataset = generate_batches(X_validation_ind,Y_validation,validation_batch_size,positiveTrainImagePath,negativeTrainImagePath, \"(Validation Generator)\")\n",
        "\n",
        "    print(\"Starting training....\")\n",
        "    model.fit(generator_x,  # Train the model using the training set...\n",
        "              epochs=num_epochs,\n",
        "              steps_per_epoch=num_train/batch_size,\n",
        "              verbose=1, validation_data=validation_dataset,\n",
        "              validation_steps=num_val/validation_batch_size,\n",
        "              callbacks=callbacks_list)\n",
        "\n",
        "    model.save('moirePattern3CNN_.h5')\n",
        "\n",
        "    test_generator= generate_batches(X_test_ind,Y_test,batch_size,positiveTrainImagePath,negativeTrainImagePath)\n",
        "    score, acc = model.evaluate(test_generator,\n",
        "                                steps=num_test/batch_size,\n",
        "                                verbose=1)\n",
        "\n",
        "    print(f\"Test score: {score}, Test accuracy: {acc}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ167EJDH8Ll"
      },
      "source": [
        "### Evaluate (Confusion Matrix etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwveaPeFIFV5"
      },
      "outputs": [],
      "source": [
        "\n",
        "def evaluate_from_indices(model, X_test_ind, y_test, batch_size,positiveTrainImagePath,negativeTrainImagePath,threshold):\n",
        "    num_test=len(y_test)\n",
        "    num_classes = 2\n",
        "    y_test = y_test.reshape(len(y_test),1)\n",
        "    Y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "    from itertools import islice\n",
        "    test_dataset = list(generate_batches(X_test_ind,Y_test,batch_size,positiveTrainImagePath,negativeTrainImagePath, \"(Test Generator)\",False, False))\n",
        "    xs,ys = list(map(list, zip(*test_dataset)))\n",
        "    ys = np.array(ys)\n",
        "    xs = np.array(xs)\n",
        "\n",
        "    yy = np.concatenate(ys)\n",
        "    y_normal = yy[:,1]\n",
        "    y_normal = y_normal.reshape(len(y_normal))\n",
        "\n",
        "\n",
        "    ll = xs[:,0]\n",
        "    ll = np.concatenate(ll)\n",
        "\n",
        "    lh = xs[:,1]\n",
        "    lh = np.concatenate(lh)\n",
        "\n",
        "    hl = xs[:,2]\n",
        "    hl = np.concatenate(hl)\n",
        "\n",
        "    hh = xs[:,3]\n",
        "    hh = np.concatenate(hh)\n",
        "\n",
        "    evaluate_list_threshold(model,X_test_ind[:len(y_normal)],[ll,hl,hl,hh],y_normal,threshold)\n",
        "    #print(test_dataset)\n",
        "\n",
        "\n",
        "def evaluate_list(model, X_test_input, y_test):\n",
        "    model_out = model.predict(X_test_input)\n",
        "    print(model_out)\n",
        "    passCnt = 0\n",
        "    TP = 0\n",
        "    TN = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    for i in range(len(y_test)):\n",
        "        if np.argmax(model_out[i, :]) == y_test[i]:\n",
        "            str_label = 'Pass'\n",
        "            passCnt = passCnt + 1\n",
        "        else:\n",
        "            str_label = 'Fail'\n",
        "\n",
        "        if y_test[i] == 1:\n",
        "            if np.argmax(model_out[i, :]) == y_test[i]:\n",
        "                TP = TP + 1;\n",
        "            else:\n",
        "                print(\"FN: \" + str(model_out[i]))\n",
        "                FN = FN + 1\n",
        "        else:\n",
        "            if np.argmax(model_out[i, :]) == y_test[i]:\n",
        "                TN = TN + 1;\n",
        "            else:\n",
        "                print(\"FP: \" + str(model_out[i]))\n",
        "                FP = FP + 1\n",
        "\n",
        "\n",
        "    start = \"\\033[1m\"\n",
        "    end = \"\\033[0;0m\"\n",
        "    print(start + 'confusion matrix (test / validation)' + end)\n",
        "    print(start + 'true positive:  ' + end + str(TP))\n",
        "    print(start + 'false positive: ' + end + str(FP))\n",
        "    print(start + 'true negative:  ' + end + str(TN))\n",
        "    print(start + 'false negative: ' + end + str(FN))\n",
        "    print('\\n')\n",
        "    print(start + 'accuracy:  ' + end + \"{:.4f} %\".format(100 * (TP + TN) / (TP + FP + FN + TN)))\n",
        "    print(start + 'precision: ' + end + \"{:.4f} %\".format(100 * TP / (TP + FP)))\n",
        "    print(start + 'recall:  ' + end + \"{:.4f} %\".format(100 * TP / (TP + FN)))\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_list_threshold(model, names, X_test_input, y_test,threshold):\n",
        "    model_out = model.predict(X_test_input)\n",
        "    #print(model_out)\n",
        "    passCnt = 0\n",
        "    TP = 0\n",
        "    TN = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    for i in range(len(y_test)):\n",
        "        pred = np.argmax(model_out[i, :])\n",
        "        if model_out[i][1] < threshold:\n",
        "            pred = 0\n",
        "\n",
        "        if pred == y_test[i]:\n",
        "            str_label = 'Pass'\n",
        "            passCnt = passCnt + 1\n",
        "        else:\n",
        "            str_label = 'Fail'\n",
        "\n",
        "        if y_test[i] == 1:\n",
        "            if pred == y_test[i]:\n",
        "                TP = TP + 1;\n",
        "            else:\n",
        "                print(\"FN: \" + str(model_out[i]) + \" \" + names[i])\n",
        "                FN = FN + 1\n",
        "        else:\n",
        "            if pred == y_test[i]:\n",
        "                TN = TN + 1;\n",
        "            else:\n",
        "                print(\"FP: \" + str(model_out[i]) + \" \" + names[i])\n",
        "                FP = FP + 1\n",
        "\n",
        "\n",
        "    start = \"\\033[1m\"\n",
        "    end = \"\\033[0;0m\"\n",
        "    print(start + 'confusion matrix (test / validation)' + end)\n",
        "    print(start + 'true positive:  ' + end + str(TP))\n",
        "    print(start + 'false positive: ' + end + str(FP))\n",
        "    print(start + 'true negative:  ' + end + str(TN))\n",
        "    print(start + 'false negative: ' + end + str(FN))\n",
        "    print('\\n')\n",
        "    print(start + 'accuracy:  ' + end + \"{:.4f} %\".format(100 * (TP + TN) / (TP + FP + FN + TN)))\n",
        "    print(start + 'precision: ' + end + \"{:.4f} %\".format(100 * TP / (TP + FP)))\n",
        "    print(start + 'recall:  ' + end + \"{:.4f} %\".format(100 * TP / (TP + FN)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IFNkJQIoHuP"
      },
      "source": [
        "# Run Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wquQROl7LX8Y"
      },
      "source": [
        "Before this run \"Universal Constants\" and \"Definitions and Imports\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWtFJFO_vO6E"
      },
      "outputs": [],
      "source": [
        "\n",
        "def run_train(positiveTrainImagePath,negativeTrainImagePath):\n",
        "\n",
        "    # Çok uzun sürüyor o yüzden şimdilik iptal, ama drive'dan local'e kopyadıktan sonra yüklemeler çok daha hızlı oluyor o yüzden bazı durumlarda faydalı olabilir:\n",
        "    # En iyisi aslında drive'da zip tutup onu buraya kopyalayıp unziplemek olur operasyon öncesi\n",
        "\n",
        "    # positiveTrainImagePath = copyPathIfDrive(positiveTrainImagePath)\n",
        "    # negativeTrainImagePath = copyPathIfDrive(negativeTrainImagePath)\n",
        "\n",
        "    epochs = 10\n",
        "    batch_size = 32\n",
        "    validation_batch_size = 32\n",
        "    validation_percent=0.1\n",
        "    test_percent=0.1\n",
        "\n",
        "    # _HL.tiff, _LL.tiff gibi band'lerin olduğu klasörden okuyup yapıyor her şeyi (positif için bir klasör, negatif içinse another klasör):\n",
        "    X_index_shuff, Y_shuff = loadXandY(positiveTrainImagePath,negativeTrainImagePath)\n",
        "\n",
        "    X_train_ind, X_test_ind, y_train, y_test = calculate_the_train_test_split_indices_my(X_index_shuff,Y_shuff,test_percent)\n",
        "\n",
        "    model = trainCNNModel_my(X_train_ind, X_test_ind, y_train, y_test,epochs, batch_size, validation_batch_size, validation_percent, positiveTrainImagePath,negativeTrainImagePath)\n",
        "\n",
        "    return\n",
        "\n",
        "run_train('/content/unzip_discard_12/discard_crop_bright_12 copy','/content/unzip_accept_12/accept_crop_bright_12')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-I8P7ee6pZq"
      },
      "source": [
        "# Run Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wrSCjxO69FB"
      },
      "source": [
        "Before this run \"Universal Constants\" and \"Definitions and Imports\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YbrMNBD6qz1"
      },
      "outputs": [],
      "source": [
        "def load_model(file_name='moirePattern3CNN_.h5'):\n",
        "    CNN_model = createModel(HEIGHT, WIDTH, 1, 2)\n",
        "    CNN_model.load_weights(file_name)\n",
        "    return CNN_model\n",
        "\n",
        "def run_test(positiveTrainImagePath,negativeTrainImagePath):\n",
        "    test_percent=0.1\n",
        "    batch_size = 32\n",
        "\n",
        "    # _HL.tiff, _LL.tiff gibi band'lerin olduğu klasörden okuyup yapıyor her şeyi (positif için bir klasör, negatif içinse another klasör):\n",
        "    X_index_shuff, Y_shuff = loadXandY(positiveTrainImagePath,negativeTrainImagePath)\n",
        "\n",
        "    X_train_ind, X_test_ind, y_train, y_test = calculate_the_train_test_split_indices_my(X_index_shuff,Y_shuff,test_percent)\n",
        "\n",
        "    model = load_model()\n",
        "\n",
        "    evaluate_from_indices(model, X_test_ind, y_test, batch_size , positiveTrainImagePath,negativeTrainImagePath,0.75)\n",
        "\n",
        "run_test('/content/drive/MyDrive/fraudfull/brighttancrop/discard_crop_bright_12','/content/drive/MyDrive/fraudfull/brighttancrop/accept_crop_bright_12')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Extm30YaIN6c"
      },
      "source": [
        "# Pre-processing (Performed once on data, saved)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBrcjIh6nZRU"
      },
      "source": [
        "## Create Training Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPsRpaEGy0jJ"
      },
      "source": [
        "CreateTrainingData.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xDR_kAeiy5Jp",
        "outputId": "49ea6311-9b9d-4f65-c9f0-a9819257bfac"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import argparse\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "#from haar2D import fwdHaarDWT2D\n",
        "count = 0\n",
        "# The training images need to be put in two folders. positiveImages and negativeImages. positiveImages are the images which are captured from the display devices and has the presence of stron or weak Moiré patterms in it. negativeImages are the ones without Moiré Patterns (i.e. the images which are not captured from the display devices)\n",
        "\n",
        "\n",
        "\n",
        "BIG_SIZE= max(WIDTH,HEIGHT)*2 #2000 #1000\n",
        "SMALL_SIZE=min(WIDTH,HEIGHT)*2 #1500 #750\n",
        "\n",
        "\n",
        "\n",
        "# folders to store training data\n",
        "positiveTrainImagePath = '/content/drive/MyDrive/fraudfull/discard_13'\n",
        "negativeTrainImagePath = '/content/drive/MyDrive/fraudfull/accept_13'\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    global positiveTrainImagePath\n",
        "    global negativeTrainImagePath\n",
        "\n",
        "    positiveImagePath = (args.positiveImages)\n",
        "    negativeImagePath = (args.negativeImages)\n",
        "\n",
        "\n",
        "    if (args.train == 0):\n",
        "        positiveTrainImagePath = '/content/drive/MyDrive/fraudfull/discard_13'\n",
        "        negativeTrainImagePath = '/content/drive/MyDrive/fraudfull/accept_13'\n",
        "    else:\n",
        "        positiveTrainImagePath = ''\n",
        "        negativeTrainImagePath = ''\n",
        "\n",
        "    createTrainingData(positiveImagePath, negativeImagePath)\n",
        "\n",
        "\n",
        "# The wavelet decomposed images are the transformed images representing the spatial and the frequency information of the image. These images are stored as 'tiff' in the disk, to preserve that information. Each image is transformed with 180 degrees rotation and as well flipped, as part of data augmentation.\n",
        "\n",
        "def transformImageAndSave(image, f, customStr, path):\n",
        "    cA, cH, cV, cD = fwdHaarDWT2D(image);\n",
        "    global count\n",
        "    count +=1\n",
        "    fileName = (os.path.splitext(f)[0])\n",
        "    fLL = (f.replace(fileName, fileName + '_' + customStr + 'LL')).replace('.jpg', '.tiff')\n",
        "    fLH = (f.replace(fileName, fileName + '_' + customStr + 'LH')).replace('.jpg', '.tiff')\n",
        "    fHL = (f.replace(fileName, fileName + '_' + customStr + 'HL')).replace('.jpg', '.tiff')\n",
        "    fHH = (f.replace(fileName, fileName + '_' + customStr + 'HH')).replace('.jpg', '.tiff')\n",
        "    cA = Image.fromarray(cA)\n",
        "    cH = Image.fromarray(cH)\n",
        "    cV = Image.fromarray(cV)\n",
        "    cD = Image.fromarray(cD)\n",
        "    cA.save(join(path, fLL))\n",
        "    cH.save(join(path, fLH))\n",
        "    cV.save(join(path, fHL))\n",
        "    cD.save(join(path, fHH))\n",
        "    print(count)\n",
        "\n",
        "\n",
        "def augmentAndTrasformImage(f, mainFolder, trainFolder):\n",
        "    try:\n",
        "        img = Image.open(join(mainFolder, f))\n",
        "    except:\n",
        "        print('Error: Couldnt read the file {}. Make sure only images are present in the folder'.format(f))\n",
        "        return None\n",
        "\n",
        "    w, h = img.size\n",
        "    if h > w:\n",
        "        img = img.resize((SMALL_SIZE, BIG_SIZE))\n",
        "    else:\n",
        "        img = img.resize((BIG_SIZE, SMALL_SIZE))\n",
        "\n",
        "    imgGray = img.convert('L')\n",
        "    wdChk, htChk = imgGray.size\n",
        "    if htChk > wdChk:\n",
        "        imgGray = imgGray.rotate(-90, expand=1)\n",
        "        print('training image rotated')\n",
        "    transformImageAndSave(imgGray, f, '', trainFolder)\n",
        "\n",
        "    imgGray = imgGray.transpose(Image.ROTATE_180)\n",
        "    transformImageAndSave(imgGray, f, '180_', trainFolder)\n",
        "\n",
        "    imgGray = imgGray.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "    transformImageAndSave(imgGray, f, '180_FLIP_', trainFolder)\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def createTrainingData(positiveImagePath, negativeImagePath):\n",
        "    # get image files by classes\n",
        "    positiveImageFiles = [f for f in listdir(positiveImagePath) if (isfile(join(positiveImagePath, f)))]\n",
        "    negativeImageFiles = [f for f in listdir(negativeImagePath) if (isfile(join(negativeImagePath, f)))]\n",
        "\n",
        "    positiveCount = len(positiveImageFiles)\n",
        "    negativeCount = len(negativeImageFiles)\n",
        "\n",
        "    print('positive samples: ' + str(positiveCount))\n",
        "    print('negative samples: ' + str(negativeCount))\n",
        "\n",
        "    # create folders (not tracked by git)\n",
        "    if not os.path.exists(positiveTrainImagePath):\n",
        "        os.makedirs(positiveTrainImagePath)\n",
        "    if not os.path.exists(negativeTrainImagePath):\n",
        "        os.makedirs(negativeTrainImagePath)\n",
        "\n",
        "    Knegative = 0\n",
        "    Kpositive = 0\n",
        "    # create positive training images\n",
        "    for f in positiveImageFiles:\n",
        "        ret = augmentAndTrasformImage(f, positiveImagePath, positiveTrainImagePath)\n",
        "        if ret == None:\n",
        "            continue\n",
        "        Kpositive += 3\n",
        "    # create negative training images\n",
        "    for f in negativeImageFiles:\n",
        "        ret = augmentAndTrasformImage(f, negativeImagePath, negativeTrainImagePath)\n",
        "        if ret == None:\n",
        "            continue\n",
        "        Knegative += 3;\n",
        "\n",
        "    print('Total positive files after augmentation: ', Kpositive)\n",
        "    print('Total negative files after augmentation: ', Knegative)\n",
        "\n",
        "\n",
        "def parse_arguments(argv):\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument('positiveImages', type=str, help='Directory with positive (Moiré pattern) images.')\n",
        "    parser.add_argument('negativeImages', type=str, help='Directory with negative (Normal) images.')\n",
        "    parser.add_argument('train', type=int, help='0 = train, 1 = test')\n",
        "\n",
        "    return parser.parse_args(argv)\n",
        "\n",
        "args = parse_arguments(['/content/drive/MyDrive/fraudfull/cropped_discard(0.6)','/content/drive/MyDrive/fraudfull/cropped_accept',0])\n",
        "main(args)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main(parse_arguments(sys.argv[1:]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1sumqu4ng85"
      },
      "source": [
        "## Haar2D (Wavelet Transform)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsQkAW0Jy_L2"
      },
      "source": [
        "haar2D\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soAfTK8TzAo9"
      },
      "outputs": [],
      "source": [
        "# This function(fwdHaarDWT2D) computes the 2D Wavelet Transform in the image. All the input images are passed through a Haar Wavelet Decomposition module, to get the LL, LH, HL and HHH component of the image\n",
        "\n",
        "import numpy as np\n",
        "import pywt\n",
        "\n",
        "\n",
        "def splitFreqBands(img, levRows, levCols):\n",
        "    halfRow = int(levRows / 2)\n",
        "    halfCol = int(levCols / 2)\n",
        "    LL = img[0:halfRow, 0:halfCol]\n",
        "    LH = img[0:halfRow, halfCol:levCols]\n",
        "    HL = img[halfRow:levRows, 0:halfCol]\n",
        "    HH = img[halfRow:levRows, halfCol:levCols]\n",
        "\n",
        "    return LL, LH, HL, HH\n",
        "\n",
        "\n",
        "\n",
        "def haarDWT1D(data, length):\n",
        "    avg0 = 0.5;\n",
        "    avg1 = 0.5;\n",
        "    dif0 = 0.5;\n",
        "    dif1 = -0.5;\n",
        "    temp = np.empty_like(data)\n",
        "    temp = temp.astype(float)\n",
        "    h = int(length / 2)\n",
        "    for i in range(h):\n",
        "        k = i * 2\n",
        "        temp[i] = data[k] * avg0 + data[k + 1] * avg1;\n",
        "        temp[i + h] = data[k] * dif0 + data[k + 1] * dif1;\n",
        "\n",
        "    data[:] = temp\n",
        "\n",
        "\n",
        "\n",
        "# computes the homography coefficients for PIL.Image.transform using point correspondences\n",
        "def fwdHaarDWT2D(img):\n",
        "    img = np.array(img)\n",
        "    levRows = img.shape[0];\n",
        "    levCols = img.shape[1];\n",
        "    img = img.astype(float)\n",
        "    for i in range(levRows):\n",
        "        row = img[i, :]\n",
        "        haarDWT1D(row, levCols)\n",
        "        img[i, :] = row\n",
        "    for j in range(levCols):\n",
        "        col = img[:, j]\n",
        "        haarDWT1D(col, levRows)\n",
        "        img[:, j] = col\n",
        "\n",
        "    return splitFreqBands(img, levRows, levCols)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dR8fiefnoOy"
      },
      "source": [
        "## Image Crop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9MEgqALP2NN"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img=Image.open('/content/drive/MyDrive/workplace.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlFEENKqQ2yH"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "5Zc4bDioSEi0",
        "outputId": "18856656-ce52-4dc8-9675-f4647923ce66"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "img=Image.open('/content/drive/MyDrive/train2/positiveimages/oriented_20200921t123717_0b092db6_8fb2_4651_a0ae_86016f997e10.jpg')\n",
        "frac = 0.60\n",
        "img.size[0]*frac\n",
        "left = img.size[0]*((1-frac)/2)\n",
        "upper = img.size[1]*((1-frac)/2)\n",
        "right = img.size[0]-((1-frac)/2)*img.size[0]\n",
        "bottom = img.size[1]-((1-frac)/2)*img.size[1]\n",
        "cropped_img = img.crop((left, upper, right, bottom))\n",
        "print(cropped_img.size)\n",
        "plt.imshow(cropped_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEeRO0Hqxu_E"
      },
      "outputs": [],
      "source": [
        "mypath = r'/content/drive/MyDrive/fraudfull/discard/'\n",
        "directory = r'/content/drive/MyDrive/fraudfull/cropped_discard(0.6)/'\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import cv2\n",
        "onlyfiles = [ f for f in listdir(mypath) if isfile(join(mypath,f)) ]\n",
        "print(onlyfiles[0])\n",
        "print(len(onlyfiles))\n",
        "for n in range(0, len(onlyfiles)):\n",
        "  img =Image.open(mypath+onlyfiles[n])\n",
        "  print(\"original \"+str(n)+\"th image size is: \"+str(img.size))\n",
        "  cropped_img = Image.open(directory+onlyfiles[n])\n",
        "  print(\"cropped \"+str(n)+\"th image size is: \"+str(cropped_img.size))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvB0nRMlqnrG",
        "outputId": "bd1c9705-fe0b-4d1c-b1fe-8076056f962b"
      },
      "outputs": [],
      "source": [
        "mypath = r'/content/drive/MyDrive/fraudfull/accept/'\n",
        "directory = r'/content/drive/MyDrive/fraudfull/cropped_accept/'\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import cv2\n",
        "onlyfiles = [ f for f in listdir(mypath) if isfile(join(mypath,f)) ]\n",
        "print(onlyfiles[0])\n",
        "print(len(onlyfiles))\n",
        "for n in range(0, len(onlyfiles)):\n",
        "  img=Image.open(mypath + onlyfiles[n])\n",
        "  filename = directory + onlyfiles[n]\n",
        "  frac = 0.60\n",
        "  left = img.size[0]*((1-frac)/2)\n",
        "  upper = img.size[1]*((1-frac)/2)\n",
        "  right = img.size[0]-((1-frac)/2)*img.size[0]\n",
        "  bottom = img.size[1]-((1-frac)/2)*img.size[1]\n",
        "  cropped_img = img.crop((left, upper, right, bottom))\n",
        "  cropped_img = cropped_img.save(os.path.join(directory,onlyfiles[n]))\n",
        "  print(str(n) +\"th image saved\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy04HoMS6IEm"
      },
      "source": [
        "# CropBrightest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UccHaXn36LhK"
      },
      "outputs": [],
      "source": [
        "##Takes the brightest part of the image for better moiré detection.\n",
        "\n",
        "from tkinter import Image\n",
        "from PIL import Image, ImageStat\n",
        "import glob\n",
        "import os\n",
        "from enum import Enum\n",
        "import math\n",
        "import os\n",
        "from os import listdir\n",
        "\n",
        "\n",
        "dict_all = {}\n",
        "\n",
        "def brightness( im_file ): #computes overall brightness value of the given im_file\n",
        "   im = Image.open(im_file)\n",
        "   stat = ImageStat.Stat(im)\n",
        "   r,g,b = stat.mean\n",
        "   res =  math.sqrt(0.299*(r**2) + 0.587*(g**2) + 0.114*(b**2))\n",
        "   #dict_all[im_file] = res\n",
        "   return res\n",
        "\n",
        "directory = '' #To store all cropped images for brightness function to use.\n",
        "mypath = '' #Images to be cropped.\n",
        "brightest_image_path ='' #folder to save brightest part of the image.\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import os\n",
        "from os import listdir\n",
        "# get the path/directory\n",
        "brightest_image_list = []\n",
        "def find_brightest_square():\n",
        "    for images in os.listdir(mypath):\n",
        "        brightness_values ={}\n",
        "        img = Image.open(os.path.join(mypath,images))\n",
        "        frac = 0.70\n",
        "        square_dict = {'upper_left':[0,img.size[0]*frac,0,img.size[1]*frac],\n",
        "                   'upper_right':[img.size[0]-img.size[0]*frac,img.size[0],0,img.size[1]*frac],\n",
        "                   'bottom_left':[0,img.size[0]*frac,img.size[1]-img.size[1]*frac,img.size[1]],\n",
        "                   'bottom_right':[img.size[0]-img.size[0]*frac,img.size[0],img.size[1]-img.size[1]*frac,img.size[1]],\n",
        "                       'center': [img.size[0]*((1-frac)/2),img.size[0]-((1-frac)/2)*img.size[0],img.size[1]*((1-frac)/2),img.size[1]-((1-frac)/2)*img.size[1]]}\n",
        "        for squares in square_dict:\n",
        "            coordinates = square_dict.get(squares)\n",
        "            print(coordinates)\n",
        "            left = coordinates[0]\n",
        "            right = coordinates[1]\n",
        "            upper = coordinates[2]\n",
        "            bottom = coordinates[3]\n",
        "            cropped_img = img.crop((left, upper, right, bottom))\n",
        "            direc = os.path.join(directory,squares+images)\n",
        "            cropped_img.save(direc)\n",
        "            res = brightness(direc)\n",
        "            brightness_values[squares+images] =res\n",
        "        max_key = max(brightness_values, key=brightness_values.get)\n",
        "        max_img = Image.open(os.path.join(directory,max_key))\n",
        "        max_img.save(os.path.join(brightest_image_path,max_key))\n",
        "find_brightest_square()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "rxmUaS56OELp",
        "EOaE9E0unwbm",
        "Extm30YaIN6c",
        "OBrcjIh6nZRU"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
